# Master of Applied AI SKORT Logbook (Dutch)

# Log
> | Week       | Student(en)        | Samenvatting van werk                        | Volgende week                              |
> |------------|--------------------|----------------------------------------------|--------------------------------------------|
> |     1      | Kristo, Oscar en Sander | Brainstormsessie over ideeën, ontwerpworkshop en onderzoek naar relevante informatie. | Onderzoek Domeinkennis (Kristo), Bestaande oplossingen (Oscar), Behoeftes doelgroep (Sander). Scenario/Storyboard uitwerken. Flow diagram maken. Basiskennis opdoen NLP technieken.|
> |     2      | Kristo, Oscar en Sander | Flowchart gemaakt, Level of Control opgezet, Storyboard uitgewerkt, Scraping van HTML en PDF files, Paper prototype gemaakt en uitgewerkt  | Details van AI modellen uitwerken, controle en impact van fouten, architectuur AI model opstellen  |
> |     3      | Kristo, Oscar en Sander | KeyBERT experimenten, Transformer experimenten, Controle en impact van AI, Uitwerking details van AI modellen, Paperprototype testing binnen de klas | Paper prototype testing buiten de klas, experimentatie met moeilijksgraad bepalen en verdere transformer modellen. Value alignment |    
> |     4      | Kristo, Oscar en Sander | Keyword extraction comparisons, Paper Prototype getest buiten de klas, SKORT Tool gemaakt. | Word difficulty, peer assessment voorbereiden, Tool uitwerken tot eerste iteratie doelen. |
> |     5      | Kristo, Oscar en Sander | Presentatie gemaakt voor peer-review, Feedback in het logboek geordend en bijgevuld, AI terminologie, PKE voor keyword extraction, onderzoek gedaan naar transfer learning naar keyword extraction, MoSCoW analyse opgesteld, laatste protoytpe V1 versie gemaakt voor vrijdag (eerste iteratie | Logboek aanvullen/aanpassen voor vrijdag, Python prototype testen met testpersonen |
> |     6      | Kristo, Oscar en Sander | Logboek aangepast/aangevuld, geëxperimenteerd met zelf trainbare modellen. | Kerstvakantie |
> |     7      | Kristo, Oscar en Sander | Draft opgezet voor rationale in Overleaf en de eerste tekst erin geschreven; Verder gewerkt aan een summarizer model, question generation modelling en AI term definition search; Logboek bijgewerkt met huidige voortgang | Voortgang over de modellen in het logboek volledig verwerken, eerste versie rationale schrijven en opsturen naar coach Pascal | 
> |     8      | Kristo, Oscar en Sander | Aan rationale gewerkt, prototype bijgewerkt, AI definities voltooid, ontwerp review feedback verwerkt, laatste testsessie uitgevoerd | Rationale draft afmaken voor vrijdag; prototype afmaken voor zondag, logboek bijvullen | 
> |     9      | Kristo, Oscar en Sander | (Geen coachgesprek deze week gehad), resultaten laatste testsessie gewerkt, laatste aanpassingen prototype doorgevoerd, rationale afgemaakt, expo gehouden | High-Stake | 

# Ideeën uit brainstormsessie en keuze
 - Automatische quiz generatie
 - Emotie binnen een tekst bepalen
 - Spraakherkenning met zoekfunctie voor een specifieke doelgroep
 - Papieren tekst inscannen voor samenvatten/highlighten/vertalen
 - Markeren van stukken die iemand niet begrijpt en relevante termen opzoeken op internet
 - Papieren tekst omzetten
 - Automatische vertaler
 - Tekstniveau bepalen 
 - "Woord-voor-woord" systeem snelheid bepalen aan de hand van moeilijksheidgraad
 - Systeem dat elk woord aanpast zodat het minder verwerktijd kost voor het brein
 - Dikgedrukt begin van elk woord voor snel door tekst lezen
 - Bias detector voor teksten
 - Witregel na een lastige zin
 - Kernwoorden/Kernzinnen uit de tekst halen
 - Meningen van feiten scheiden
 - Hyperlinks plaatsen op relevante termen
 - Spelfouten correctie vóór het lezen
 - Definities/Synoniemen vinden voor lastige woorden
 - Leestijd persoonlijk bepalen
 - Research papers samenvatten
 - Negatief/Positief annotatie bij persoon
 - Text to speech
 - Literatuurbespreking samenvatting maker
 - Eye tracker voor dyslexie


Uiteindelijk is, in overleg met de coach, ervoor gekozen om vier van de bovenstaande ideeën in één tool verwerken voor de eerste iteratie. Deze ideeën waren:
- Tekstniveau bepalen
- Leestijd persoonlijk bepalen
- Definities/Synoniemen vinden voor lastige woorden
- Kernwoorden/Kernzinnen uit de tekst halen

Deze combinatie van vier ideeën achten wij haalbaar binnen de beschikbare tijd voor de eerste iteratie en daarnaast achten wij het mogelijk om een passende doelgroep te kunnen kiezen. Bovendien denken wij door deze ideeën uit te werken, dat aan de beschikbare leerdoelen voldaan kan worden.   


# Definitie van succes 

**Team**

> | Definitie van succes | Mogelijke problemen | Grote risico's | Wat heb je nodig gerustgesteld te worden? |
> |----------------------|---------------------|----------------|-------------------------------------------|
> | Een gerealiseerd en werkend prototype, dat een daadwerkelijke oplossing kan bieden voor de wensen/problemen van de stakeholders. | Te brede projectscope, oplossing past  niet op de behoeftes van de doelgroep. | Geen of te weinig geschikte datasets aanwezig voor het probleem, werkdruk buiten het project om | Positieve feedback uit testsessies met proefpersonen, positieve feedback uit coaching sessies. Resultaten. | 

 - **Individueel (Kristo)**

 >| Definitie van succes | Mogelijke problemen | Grote risico's | Wat heb je nodig gerustgesteld te worden? |
 >|----------------------|---------------------|----------------|-------------------------------------------|
 >| NLP basis beheersen en het prototype begrijpen en werkend krijgen | Ik heb nog erg weinig kennis van NLP, dus technisch op masterniveau komen gaat veel tijd kosten | Hoge werkdruk | Positieve reactie vanuit de betrokkenen bij het project. |

 - **Individueel (Oscar)**

>| Definitie van succes | Mogelijke problemen | Grote risico's | Wat heb je nodig gerustgesteld te worden? |
>|----------------------|---------------------|----------------|-------------------------------------------|
>| Een bruikbare nlp toepassing gemaakt te hebben en deze goed beargumenteren / documenteren | Andere vakken / paper die tijd wegneemt van het project. Gemaakt product/project onder verwachting van coach/docenten | Ziekte(winter tijd), Drukte buitenom studie | Verwachting vanuit coach / docenten duidelijk te hebben.|

- **Individueel (Sander)**

>| Definitie van succes | Mogelijke problemen | Grote risico's | Wat heb je nodig gerustgesteld te worden? |
>|----------------------|---------------------|----------------|-------------------------------------------|
>|Een goede bijdrage leveren aan het realiseren van een werkend prototype, dat een daadwerkelijke oplossing kan bieden voor de wensen/problemen van de stakeholders. | Geen duidelijke doelstelling of afbakening, waardoor we verdwaald raken in de opzet en mogelijke opties binnen het project. | Te veel werk buiten het project om. | Een bevestiging van coach/docenten dat wij(of ik) goed op weg zijn. |

# Process Flow
## Huidig proces (Oscar)
1. Student vindt een paper op het web.
2. Student probeert de grootte, moeilijkheidsgraad en onderwerpen van de paper te bepalen.
3. Student begint de paper te lezen wanneer hij/zij deze geschikt acht.
4. Student leest in de paper een onbekende term.
5. Student zoekt de term op in een tweede tabblad (optioneel, als de student niet te lui is).
6. Student leest over de term op een externe website in het tweede tabblad.
7. Student gaat verder met het lezen van de paper.
8. Terug naar stap 2, totdat complete paper gelezen is.

## Toekomstig proces (Kristo)
1. De student vindt een paper op het web.
2. De tool berekent belangrijke informatie over de paper (leestijd, moeilijkheisgraad) en extraheert de lastige/belangrijke termen uit de tekst.
3. De student ziet in één opslag of de paper geschikt voor hem/haar is om te lezen
4. De student leest een onbekende term.
5. Per term kan de student de betekenis vinden binnen de tool ter verduidelijking.
6. De student gaat verder met het lezen van de paper

# Domeinkennis leerstrategieën HBO-studenten (Kristo)
## soorten leerstrategieën: oriënterend, begrijpend, analytisch en herhaald. 
https://www.havohbo.nl/wp-content/uploads/Teksten-lezen-en-leren.pdf 

Oriënterend lezen/zoekend lezen:
Oriënterend lezen wordt ook wel globaal lezen of zoekend lezen genoemd, omdat je je een indruk vormt van de tekst en op zoek gaat naar de structuur. In de praktijk is deze techniek vooral handig voor een eerste kennismaking met de tekst.

Begrijpend lezen: 
Bij begrijpend lezen gaat het erom dat je kind de tekst die hij leest ook echt begrijpt. Meestal toetst een leerkracht dat tekstbegrip met vragen en opdrachten. Die vragen kunnen gaan over de inhoud van een deel van de tekst.

Analytisch lezen: 
Analytisch lezen houdt in dat je probleemoplossend kunt nadenken door een probleem of vraagstuk vanuit verschillende invalshoeken te bekijken. Ook kun je snel hoofd- en bijzaken onderscheiden. Analytisch vermogen lijkt sterk op kritisch denken.

Herhaald lezen: 
Herhaald lezen van teksten bevordert het vloeiend lezen en automatiseren bij zwakke lezers. Het maakt niet uit of dezelfde tekst herhaald wordt gelezen of dat meerdere teksten worden gelezen. Waarschijnlijk is de grote hoeveelheid tijd die wordt gespendeerd aan lezen een van de cruciale componenten.

## Reden en doel van de tool
Highlighten en herlezen van stukken tekst biedt minimaal effect bij HBO studenten (Nationale Onderwijs Gids, 2013). Zelfoverhoring, oefenvragen en het over langere tijd verspreiden van leersessies zijn wel effectief.

Hoe effectief studenten leren hangt niet enkel af van de manier waarop ze een tekst benaderen: ‘Door het bevorderen van levensvaardigheden gaan studenten beter in hun vel zitten en worden zij sociaal en emotioneel vaardiger. Hierdoor zijn zij in staat om zichzelf te motiveren en verbeteren hun leerprestaties.’ (Hogeschool Leiden, 2021). Studenten hebben vaak de nodige stress, omdat ze vaak veel werken, een druk sociaal leven hebben en bezig zijn met sociale media (Dopmeijer, 2021). Daarnaast vinden studenten het lastig om hulp te vragen, hun gedrag te sturen, zich betrokken te voelen bij onderwijsactiviteiten en (kritisch) te communiceren in de collegezaal (Hogeschool Leiden, 2019). Studenten hebben verder vaak ondersteuning nodig om gemotiveerd te blijven (Crone, 2014) en ze kunnen extra vatbaar zijn voor depressieve klachten. Levensvaardigheden dragen bij aan studiesucces en motivatie om te leren. Zie Hoofdstuk 19 van Hoe Leren Studenten (Hogeschool Leiden, 2021) voor meer informatie over het investeren in studiesucces met behulp van levensvaardigheden.

Honoursstudenten in het HBO houden zich tijdens het leren bezig met of de theorieën, interpretaties en conclusies goed onderbouwd zijn met bewijs (Tijdschrift voor Hoger Onderwijs, 2014). Daarnaast stellen deze honoursstudenten gerichte doelen voor hunzelf. Honoursstudenten onderscheiden zich van reguliere studenten door een hogere mate van kritisch denken en zelfregulerend leren. Om reguliere studenten slimmer te maken is vanuit hunzelf een grote mate van interesse en motivatie nodig. Door informatie bij lastige woorden te plaatsen die de student kan bestuderen en bekritiseren, wordt de kans op interesse vergroot. Bij interesse komt vaak motivatie kijken, waardoor de docent vooral kan optreden als begeleider, zodat de student meer zelfgereguleerd kan studeren. 

Het doel van de te ontwikkelen tool is om interesse op te wekken in het eigen vakdomein bij studenten die minder motivatie hebben, waardoor ze beter gaan presteren. Met behulp van de tool wordt de stap kleiner om de betekenis en interpretatie van belangrijke en lastige woorden uit te zoeken. Zodra de studenten meer domeinkennis hebben is de leerstof beter te volgen en wordt sneller interesse en motivatie opgewekt bij de student, wat de studieprestaties bevorderd. Daarnaast is het doel om de concentratie van de student te waarborgen. Als de student elk woord dat hij/zij niet begrijpt moet opzoeken in de browser verliest de student telkens de concentratie. Door definities van belangrijke/lastige woorden in de tool weer te geven leest de student sneller, makkelijker en met bewaarde concentratie door de tekst.

## Bronnen
Dopmeijer, J.M. (2021). Running on empty. The impact of challenging student life on wellbeing and academic performance. Proefschrift. Amsterdam: UVA

Hogeschool Leiden (2019). Levensvaardigheden voor studenten. Leiden: Hogeschool Leiden, lectoraat Ouderschap & Ouderbegeleiding

Motivatie en leerstrategieën van honoursstudenten (2014): https://oadoi.org/10.5553/tvho/016810952014032001009 

Minimale voordelen van highlighten en herlezen van stukken tekst (HBO). Zelfoverhoring, oefenvragen en het over langere tijd verspreiden van leersessies zijn wel effectief: https://www.nationaleonderwijsgids.nl/hbo/nieuws/15139-markeren-van-studiestof-geen-optimale-leermethode.html 

Hoe leren studenten in het hoger beroepsonderwijs (Hogeschool Leiden, 2021): https://www.hsleiden.nl/binaries/content/assets/hsl/over-hl/hl-canon-hoe-leren-studenten.pdf 

# Bestaande oplossingen (Oscar)
Keybert python library lijkt erg makkelijk toe te passen.
https://github.com/MaartenGr/KeyBERT    
Informatie over alles van nlp met verschillende bronnen/libraries/tutorials  
https://github.com/keon/awesome-nlp    
Bert 101 uitleg  
https://huggingface.co/blog/bert-101  
Datasets:  
	https://github.com/LIAAD/KeywordExtractor-Datasets
https://github.com/LIAAD/KeywordExtractor-Datasets#Inspec
	https://github.com/LIAAD/KeywordExtractor-Datasets#Krapivin
	https://www.kaggle.com/datasets/kkhandekar/word-difficulty
	https://huggingface.co/datasets/memray/keyphrase/tree/main/kp20k


# Behoeftes doelgroep (Sander)
## Interviews met doelgroep

**Testpersoon 1**
 - Hoe ga je om met lastige termen in teksten?
    - Ik probeer eerst uit de zinnen rondom de term af te leiden. Als dit niet voldoende is,  
   voer ik de term in op Google, in de hoop een duidelijke betekenis te kunnen vinden.
 - Hoe bepaal je de moeilijkheidsgraad van een tekst?
    - Ik kijk voornamelijk naar gebruikte formules en de resultaten. Daarnaast lees ik de 
   abstract of intro om de moeilijkheidsgraad van de tekst in te kunnen schatten.
 - Zou je geïnteresseerd zijn in de voor jouw gepersonaliseerde leestijd voor teksten?
    - Ja, het helpt met het inschatten van de tekst. Als ik iets snel wil weten/begrijpen, 
    ben ik niet van plan 30 minuten te gaan lezen.
 - Zorgt het beter begrijpen van de tekst voor meer interesse rond het AI onderwerp?
    - Ja, als ik het beter begrijp kan ik er ook beter aan relateren, als je weet hoe iets 
   werkt dan krijg je der ook meer interesse voor. 

**Testpersoon 2**
 - Hoe ga je om met lastige termen in teksten?
    - Ik ben dyslectisch persoonlijk, dus ik lees er eerst een paar keer overheen en  
   probeer het uit de tekst te kunnen afleiden. Als het een Engelse term is vertaal ik het 
   eerst. Tenslotte zoek ik op Google naar de Nederlandse definitie. 
 - Hoe bepaal je de moeilijkheidsgraad van een tekst?
    - Ik denk dat ik zelf wel een redelijk niveau bezit, dus ik maak me niet zo druk over de 
              moeilijkheidsgraad van een tekst
 - Zou je geïnteresseerd zijn in de voor jouw gepersonaliseerde leestijd voor teksten?
    - Ja, ik denk dat een gepersonaliseerde leestijd praktisch zou zijn.
 - Zorgt het beter begrijpen van de tekst voor meer interesse rond het AI onderwerp?
    - Ik denk het wel, als de tekst beter te begrijpen is, is het makkelijker om verder te 
              gaan met het lezen van teksten betreffende hetzelfde onderwerp.

**Testpersoon 3**
 - Hoe ga je om met lastige termen in teksten?
    -  Ik zoek meestal de term direct op, om de definitie te kunnen achterhalen. Dan nadat ik het wat meer begrijp, lees ik het in de tekst nogmaals.
 - Hoe bepaal je de moeilijkheidsgraad van een tekst?
    -  Ik kijk naar de woordkeuze en de zinsopbouw, veel vaktermen duiden meestal aan 
               dat de tekst van een wat hoger niveau zal zijn
 - Zou je geïnteresseerd zijn in de voor jouw gepersonaliseerde leestijd voor teksten?
    -  Ja, het zou fijn zijn om te weten hoe lang je met een tekst bezig zou zijn. Bovendien 
               geeft de aanduiding dat je snel door een tekst heen kunt gaan een positieve 
               instelling voor de tekst. 
 - Zorgt het beter begrijpen van de tekst voor meer interesse rond het AI onderwerp?
    -  Als je tekst beter kunt begrijpen, geeft dit een positieve mindset rond het onderwerp 
               en zorgt voor meer leesplezier. Daarnaast wordt ik uit mijn concentratie gehaald als 
               ik meermaals termen op een browser moet opzoeken. Met behulp van de tool blijf        ik in mijn concentratie, wat me uiteindelijk positief beïnvloed rond de interesse van het onderwerp.


## Enquete binnen doelgroep
|Opleidingsniveau|Opleiding|Aantal studenten|
|------|---------|-------|
|HBO-bachelor|Business en economie|3|
|HBO-bachelor|Techniek|11|
|HBO-bachelor|CMD|6|
|HBO-bachelor|Onderwijs en voeding|2|
|WO-master|Geowetenschappen|1|
|WO-bachelor|Maatschappij en recht|1|
|HBO-bachelor/WO-master|Gezondheid|3|
|WO-master|Gedrags- en bewegingswetenschappen|1|
|WO-bachelor|Geesteswetenschappen|1|
|HBO-bachelor|Logistiek management|1|
|-|Geen huidige opleiding|4|

- Totaal aantal testpersonen: 34
- Opleidingsniveaus: HBO - WO - Master - Afgestudeerd
- Opleidingen: Business en economie - Techniek - CMD - Onderwijs en opvoeding - Geowetenschappen - Toegepaste wiskunde - Maatschappij en recht - Gezondheid - Gedrags- en bewegingswetenschappen - Geesteswetenschappen - Logistiek management

||Door eerst het abstract te lezen |Tekst skimmen |Resultaten/conclusie bekijken |Door te kijken waar de literatuur vandaan komt|Niet, ik begin gewoon met lezen|
|-----------------------------------------------------|-----|-----|------|-----|------|
|Hoe schat je de moeilijkheidsgraad van een tekst in? | 19x | 1x  | 1x   | 5x  | 13x  |    

| | Ja | Nee |
|-|----|-----|
|Heb je moeite met het lezen van Engelse teksten?| 6x | 28x |

| | Ja, met behulp van internet | Nee | 
|-|----|-----|
|Zoek je lastige termen op ter verduidelijking?| 30x | 4x |

| |Een schatting maken van de leesmoeilijkheidsgraad |Bepalen van de categorie van het artikel/boek |Verwante artikelen en boeken aanbevelen op basis van de categorie en onderwerp.|Markering van de kernzin van een alinea |Markeren van belangrijke afkortingen en jargon |
|-----------------------------------------------------------------------------------|----|----|-----|-----|-----|
|Welke van de volgende digitale hulpmiddelen zou je interessant en/of nuttig vinden?| 4x | 8x | 18x | 18x | 17x | 

# Nulmodel (Kristo)
Er is een nulmodel vastgesteld als maatstaf voor de performance bij keyword extraction. Indien SKORT beter presteert dan het nulmodel wordt de tool gezien als een goed model.

Het nulmodel wordt gedefinieerd door de 10 meest voorkomende woorden in de tekst die niet terug te vinden zijn in een lijst van 10.000 meestgebruikte woorden, te zien als kernwoorden. Als SKORT betere (human reviewed) kernwoorden vindt dan het nulmodel, wordt SKORT gezien als een goed presterend model.

# Pakket van Eisen

| Nummer | Categorie | Eis | Afkomstig van |
|--------|-----------|-----|---------------|
|   1    | Technisch | Het prototype van SKORT kan kernwoorden uit een tekst halen en deze highlighten | Doelgroep |
|   2    | Technisch | De leestijd voor de paper wordt berekend en is personaliseerbaar | Doelgroep | 
|   3    | Technisch | De moeilijksheidgraad voor de paper wordt berekend en aan de gebruiker getoond | Doelgroep |
|   4    | Technisch | Definities en Synoniemen van termen moeten in de tool op te zoeken of terug te vinden zijn | Doelgroep |
|   5    | Technisch | Gebruiker moet zelf woorden kunnen selecteren om definities over te krijgen | Doelgroep / Team  |
|   6    | Technisch | De student mag niet dommer worden van de tool; De tekst mag geen informatie verliezen | Opdracht |
|   7    | Technisch | Tool moet papers kunnen inlezen (en keywords extracten) van elke website (Scalability) | Team |
|   8    | Technisch | Gevonden kernwoorden moeten dicht, niet meer dan drie fout, bij de kernwoorden liggen die een gemiddeld persoon uit de doelgroep zou kiezen|Team|
|   9    | Technisch | Het SKORT model, voor keyword extraction, moet op gebied van performance beter presteren dan het vastgestelde nulmodel | Team |
|   10   | Ethisch   | Het SKORT model, voor keyword extraction, moet dezelfde prestatie kunnen leveren op verschillende talen. | Team |
|   11   | Ethisch   | Dataset voor kernwoordextractie moet bestaan uit teksten geschreven door een even verhouding aan mannen en vrouwen | Coach |
|   12   | Ethisch   | Gevonden kernwoorden mogen niet een bias hebben richting een bepaalde doelgroep | Team |
|   13   | Juridisch | Er mag geen informatie behouden worden over de ingeladen paper. | Auteursrecht |
|   14   | Juridisch | De gebruiker hoeft geen account aan te maken en  persoonsdata (IP-adres, naam etc.) wordt niet opgeslagen. | AVG |
|   15   | Juridisch | De gebruiker heeft het recht om zijn/haar gepersonaliseerde data (leestijd, moeilijksheidgraad) te laten verwijderen. | Recht op wissing |
|   16   | Organisatorisch | De gebruiker moet feedback kunnen teruggeven/delen aan de ontwikkelaars. | Doelgroep |
|   17   | Organisatorisch | Tool moet overzichtelijk zijn ingericht, zodat onboarding niet nodig hoeft te zijn. (Explainability)| Doelgroep |
|   18   | Organisatorisch | De SKORT tool wordt gemonitord en onderhouden door het team en zal niet worden uitbesteed | Team |

## MoSCoW Analyse
De volgende MoSCoW analyse is aan de hand van de bovengenoemde requirements opgesteld.


| |Must haves | 
|-|-------|
|1|Het prototype van SKORT kan kernwoorden uit een tekst halen en deze highlighten|
|2|De leestijd voor de paper wordt berekend en is personaliseerbaar|
|3|De moeilijksheidgraad voor de paper wordt berekend en aan de gebruiker getoond|
|4|Definities en Synoniemen van termen moeten in de Tool op te zoeken of terug te vinden zijn|
|6|De student mag niet dommer worden van de tool; De tekst mag geen informatie verliezen|
|7|Het SKORT model, voor keyword extraction, moet op gebied van performance beter presteren dan het vastgestelde nulmodel|
|8|De SKORT tool wordt gemonitord en onderhouden door het team en zal niet worden uitbesteed|
|9|Gebruiker moet zelf woorden kunnen selecteren om definities over te krijgen|


| |Should haves | 
|-|-------|
|10|Tool moet papers kunnen inlezen (en keywords extracten) van elke website (Scalability)|
|11|Er mag geen informatie behouden worden over het ingeladen paper.|
|12|De gebruiker moet feedback kunnen teruggeven/delen aan de ontwikkelaars.|
|13|Tool moet overzichtelijk zijn ingericht, zodat onboarding niet nodig hoeft te zijn. (Explainability)|

| |Could haves | 
|-|-------|
|14|Gevonden kernwoorden moeten dicht, niet meer dan drie fout, bij de kernwoorden liggen die een gemiddeld persoon uit de doelgroep zou kiezen|
|15|De gebruiker hoeft geen account aan te maken en  persoonsdata (IP-adres, naam etc.) wordt niet opgeslagen|
|16|Gevonden kernwoorden mogen niet een bias hebben richting een bepaalde doelgroep|

| |Won't haves | 
|-|-------|
|17|Dataset voor kernwoordextractie moet bestaan uit teksten geschreven door een even verhouding aan mannen en vrouwen|
|18|Het SKORT model, voor keyword extraction, moet dezelfde prestatie kunnen leveren op verschillende talen.|



# Level of control (Kristo)
Onze AI-oplossing valt heeft zowel human-control als computer-automation. Omdat de gebruiker zelf kan selecteren welke tools hij/zij wilt dat toegepast worden op de tekst. De gebruiker kan daarnaast ook feedback geven op de tool door bijvoorbeeld aan te geven welk woord de gebruiker belangrijk/lastig vind waar geen verdere informatie bij staat.

![Level of Control](Levelofcontrol.png)

# Flowchart (Oscar)
![Flowchart](Flowchart_week1.png)

# Storyboard (Sander)
![Storyboard](Storyboard.png)

- Doelgroep: Studenten (die papers lezen)
- Behoefte doelgroep: Het vereenvoudigen van het vinden van de essentie van een tekst en het eenvoudig vinden van definities/omschrijvingen van vaktermen en lastige woorden in een paper.
- Wat levert de oplossing: Een tool om eenvoudig definities/omschrijvingen van vaktermen en lastige woorden te kunnen lezen, daarnaast levert het algemene nuttige informatie over de paper (moeilijkheidsgraad, leestijd etc.)

# User problem statement (Oscar)  

![User Problem Statement](UserProblemStatement.png)

# Role of AI Concept (Oscar)  

![Role of AI Concept](RoleofAIConcept.png)

# Soorten mogelijke bias (Kristo)
Er bestaat een kans op bias in SKORT. Mogelijke soorten bias die vastgesteld kunnen worden bij het gebruik van SKORT zijn:

* Demografische bias: als SKORT getraind is op teksten van blanke mannen, andere teksten mogelijk anders geinterpreteerd kunnen worden en het model niet eerlijk handelt. Daarom is het van belang dat SKORT getraind is op teksten van mensen met verschillende demografische achtergronden.
* Sociaal-culturele bias:als SKORT is getraind op teksten afkomstig van mensen uit een bepaalde cultuur, het lastig kan zijn om teksten die voortkomen uit een andere cultuur eerlijk te benaderen. Daarom is het van belang dat SKORT getraind is op teksten van diverse culturen.
* Historische bias: als SKORT is getraind op teksten geschreven in een bepaald tijdperk, kan het moeilijk zijn om teksten geschreven in een ander tijdperk goed te begrijpen. Daarom is het van belang dat SKORT getraind is op teksten van diverse tijdperken.
* Taalbias: als SKORT is getraind op teksten geschreven in het Engels, is het lastig om teksten geschreven in andere talen goed te begrijpen. Daarom is het van belang dat er alleen Engelse teksten gebruikt kunnen worden in de tool.
* Bias in bronnen: als SKORT is getraind op teksten uit bepaalde bronnen, zoals tijdschriften of websites, kan de tool vooringenomen zijn ten opichte van ideeen of perspectieven die in de bron worden voorgesteld. Daarom is het van belang dat SKORT enkel gebruikt wordt om wetenschappelijke artikelen te versimpelen.

# Evaluatie van SKORT (Kristo)
SKORT zal gevalueerd worden door:
1. De betrouwbaarheid te controleren. Het is belangrijk dat SKORT consistent presteert op allerlei soorten teksten, rekening houdend met de soorten bias, en doet wat wij zeggen dat hij moet doen.
2. De nauwkeurigheid te controleren. Dit gaan we controleren door de tool te testen met verschillende soorten teksten en te kijken of de keywords en definities die SKORT genereerd juist zijn.
3. Het gebruiksgemak wordt geevalueerd door te controleren of de UI duidelijk en logisch is aan de hand van testsessies en of SKORT niet te langzaam werkt.

# Confusion matrix (Sander)

De confusion matrix hieronder laat de mogelijke uitkomsten voor de keyword extraction uit de applicatie zien. De True Positive en de True Negative zijn de toestanden waar we naar toestreven. We focussen ons zo veel mogelijk op het voorkomen van False Negatives. Bij deze uitkomst missen we mogelijke keywords die cruciaal kunnen zijn voor de tekst. False positives worden minder erg geschat in dit geval, doordat de daadwerkelijke keywords nog steeds gemarkeerd kunnen worden. Een overvloed van keywords zou later nog gefilterd kunnen worden. Keywords of kernwoorden zijn in dit project de belangrijkste woorden uit de tekst die essentieel zijn in het begrijpen van de tekst.

| Confusion matrix | Positieve voorspelling | Negatieve voorspelling |
|------------------|------------------------|------------------------|
| Positieve waarheid | **True positive** (Het gewenste resultaat): Woorden dat in de tekst zijn gemarkeerd zijn daadwerkelijk keywords | **False negative**: Een woord dat daadwerkelijk een keyword is in de tekst wordt niet gemarkeerd    |
| Negatieve waarheid | **False positive**: Er wordt een woord gemarkeerd, maar dit is geen keyword in de tekst.                        | **True negative** (Het gewenste resultaat): Woorden dat geen keywords zijn in de tekst worden niet gemarkeerd |

# Impact op de maatschappij (Sander)

Hoewel het hier gaat om een simpele reading tool, kan de tool toch een impact uitvoeren op de maatschappij. Een positieve impact zou hierbij ons doel zijn, waarbij studenten in staat zijn om de volledig functionerende tool te kunnen gebruiken om het lezen/begrijpen van papers te kunnen vereenvoudigen. Daarnaast hopen wij hiermee overige ontwikkelaars aan te sporen om ook taalverwerkingsprojecten op te starten om studenten te kunnen helpen. 
<br> Maar de tool kan ook een (theoretische) negatieve impact op de maatschappij hebben. Denk hierbij aan het gebruik van papers die op onreglementaire wijze zijn verkregen en in de tool worden geladen (piracy). Daarnaast bestaat de kans altijd dat de tool een datalek zou kunnen krijgen, waardoor gegevens van gebruikers op straat zouden kunnen belanden (privacy).
<br> Daarentegen achten wij de kans klein op deze negatieve impact, gezien de staat van het huidige prototype en de nog lange weg van ontwikkelen voor ons. Hierom stellen wij de impact op de maatschappij op LAAG.    


# Level of automation (Sander)

![Level of automation](AutomationLevel.png)

From (Sheridan & Verplank, 1978) 

Ons prototype valt onder Level 5. Het prototype voert automatisch het AI gedeelte in de achtergrond uit wanneer de tekst wordt ingeladen, maar het is vervolgens aan de gebruiker om te selecteren welke opties te gebruiken of in te zien. Daarbij kunnen gebruikers feedback geven als zij liever iets anders zien.
# Ethische en juridische requirements (draft) (Kristo)
Er zijn een aantal ethische requirements waar de tool rekening mee moet houden. 

* Inclusiviteit: SKORT werkt voor verschillende soorten teksten, zodat het toegankelijk is voor een breed publiek.
* Privacy: er worden geen persoonlijke gegevens opgeslagen of gedeeld zonder toestemming.
* Transparantie: SKORT geeft aan hoe de tool werkt en wat de beperkingen zijn, zodat de gebruiker weet wat hij/zij kan verwachten.
* Rechten van intellectuele eigendom: SKORT gebruikt geen teksten zonder toestemming van de rechthebbende.

# Mogelijke ongewenste consequenties (Kristo)
Er zijn een aantal mogelijke ongewenste consequenties van SKORT.

* Onnauwkeurigheid: als SKORT onnauwkeurig is kan dit leiden tot verkeerde definities of een verkeerd begrip van de tekst. Dit kan leiden tot miscommunicatie of onnodige verwarring.
* Bias: als SKORT niet goed is afgestemd op verschillende soorten teksten kan dit leiden tot discriminatie of ongelijkheid in toegang tot informatie.
* Privacy-inbreuk: als SKORT onbedoeld persoonlijke gegevens opslaat of deelt zonder toestemming van de gebruiker, kan dit leiden tot een privacy-inbreuk.
* Verwarring: Als de tool onduidelijk is of als de uitleg van het model niet goed is, kan dit leiden tot verwarring bij gebruikers.
* Verlies van productiviteit: Als SKORT moeilijk te gebruiken is of als het te veel tijd kost om de resultaten te bekijken, kan dit leiden tot verlies van productiviteit.
* Negatief effect op de reputatie: Als SKORT fouten maakt of als er problemen optreden met de tool, kan dit leiden tot een negatief effect op de reputatie van SKORT.
* Onvoldoende toegang: Als niet iedereen toegang heeft tot SKORT, kan dit leiden tot ongelijkheid en oneerlijke behandeling.
* Financiële kosten: Als SKORT duur is om te gebruiken of te onderhouden, kan dit leiden tot financiële kosten voor gebruikers of organisaties.
* Incompatibiliteit met andere systemen: Als SKORT niet goed samenwerkt met andere systemen of programma's, kan dit leiden tot problemen met het gebruik van de tool of het uitvoeren van taken.

# Paper prototype (Week 2/3)

![Paper prototype](Paper_Prototype_v1.jpg)
![Foto testsessie](PPTestsessie.jpeg)

# SKORT logo en fail gracefully (Kristo)
Het logo van onze AI-tool ziet er als volgt uit.

![SKORT logo](../doc/SKORT_logo.jpeg)

Het logo is uniek en simpel. In de 'O' zit een vergrootglas gemonteerd en aan de 'T' zit een globaal wetenschappelijk artikel vast met enkele gele highlights.

Mocht het model niet werken, komt de volgende pop-up op het scherm.

![Fail gracefully](../doc/SKORT_failgracefully.png)

De foutmelding bevat humor, omdat het woord 'wrong' in deze zin een belangrijk woord is en dus gehighlight is. Het designpatroon is als volgt:
1. AI zal kernwoorden en jargon extraheren uit de tekst en korte samenvattingen kunnen genereren, definities van vaktermen kunnen geven, de gepersonaliseerde rekentijd kunnen geven en vragen kunnen genereren.
2. De gebruiker heeft de mogelijkheid om het laden van de tool te onderbreken en feedback te geven als de resultaten van de tool niet gewenst zijn.
3. Laat de resultaten aan de gebruiker zien, of de pop-up als de tool niet werkt/reageert. Kernwoorden worden gehighlight, de definities worden in tooltips bij de vaktermen geplaatst, bij het bepalen van de leestijd en moeilijkheidsgraad staat de gebruikte formule en bron hoe deze berekend zijn.
4. Zoals eerder benoemd kan de gebruiker feedback geven binnen de tool over de gewenste verwachtingen, indrukken, etc.
5. De gebruiker heeft niet de mogelijkheid om de tool direct te misbruiken.

# Keyword extraction models (Kristo)
Keyword extractie modellen vinden kernwoorden in documenten. Er zijn diverse keyword extractors die gebruikt zullen worden in dit project. Naast Spacy (Honnibal, M. & Montani, I., 2017), RAKE (Rose et al., 2010), en KeyBERT (Grootendorst, 2020) zijn er 10 PKE (Pyramid Keyword Extraction) modellen getest. Waaronder het supervised model PKE Kea ((Witten et al., 2005) getraind op de SemEval-2010 dataset (Kim et al., 2010)), maar voornamelijk unsupervised modellen die onderverdeeld kunnen worden in statistische modellen (TfIdf, KPMiner (El-Beltagy en Rafea, 2010) en YAKE (Campos et al., 2020)) en graph-based modellen (TextRank, SingleRank (Wan en Xiao, 2008), TopicRank (Bougouin et al., 2013), TopicalPageRank (Sterckx et al., 2015), PositionRank (Florescu en Caragea, 2017) en MultipartiteRank (Boudin, 2018)). 

Deze alinea is gebaseerd op het Medium artikel 'Keyword Extraction Methods - The Overview' van Godec (2021).
Statistische keyword extraction methoden zijn het minst complex. Deze statistische modellen gebruiken statistiek om kernwoorden te berekenen en een score toe te kennen. Er zit verder niks diepers achter. Graph-based modellen zijn wat complexer en genereren grafen van gerelateerde termen van het document. Deze modellen maken een graaf van de tekst, met de woorden als knopen en verbindingen tussen woorden die samen voorkomen. Met een bepaalde metriek, welke beschreven wordt in het Medium artikel 'Exploring Different Keyword Extractors — Graph Based Approaches' van Shrivastava (2020), kan bepaald worden welke woorden als kernwoorden beschouwd kunnen worden. De supervised modellen zijn nog complexer, omdat dit modellen zijn die getraind moeten worden.

* Honnibal & Montani, 2017: spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing.  
* Rose, S., Engel, D., Cramer, N. and Cowley, W. (2010): Automatic Keyword Extraction from Individual Documents. In Text Mining (eds M.W. Berry and J. Kogan). https://doi.org/10.1002/9780470689646.ch1  
* Grootendorst, 2020: KeyBERT: Minimal keywords extraction with BERT. Zenodo, https://doi.org/10.5281/zenodo.4461265  
* Kim et al., 2010: https://aclanthology.org/S10-1004/   
* El-Betagy en Rafea, 2010: https://aclanthology.org/S10-1041.pdf  
* Campos et al., 2020: YAKE! Keyword Extraction from Single Documents using Multiple Local Features. In Information Sciences Journal. Elsevier, Vol 509, pp 257-289. https://doi.org/10.1016/j.ins.2019.09.013  
Wan en Xiao, 2008: https://aclanthology.org/C08-1122.pdf  
* Bougouin et al., 2013: https://aclanthology.org/I13-1062.pdf  
* Sterckx et al., 2015: http://users.intec.ugent.be/cdvelder/papers/2015/sterckx2015wwwb.pdf  
* Florescu en Caragea, 2017: https://aclanthology.org/P17-1102.pdf  
* Boudin, 2018: https://arxiv.org/abs/1803.08721  
* PKE paper: Florian Boudin. 2016. pke: an open source python-based keyphrase extraction toolkit. In Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations, pages 69–73, Osaka, Japan. The COLING 2016 Organizing Committee.

# Keyword extraction comparison

text1 = "virtually enhancing the perception of user actions. This paper proposes using virtual reality to enhance the perception of actions by distant users on a shared application. Here, distance may refer either to space ( e.g. in a remote synchronous collaboration) or time ( e.g. during playback of recorded actions). Our approach consists in immersing the application in a virtual inhabited 3D space and mimicking user actions by animating avatars. We illustrate this approach with two applications, the one for remote collaboration on a shared application and the other to playback recorded sequences of user actions. We suggest this could be a low cost enhancement for telepresence"
- keywords1 =  ["telepresence", "animation", "avatars", "application sharing", "collaborative virtual environments"]

text2 = "Dynamic range improvement of multistage multibit Sigma Delta modulator for low oversampling ratios. This paper presents an improved architecture of the multistage multibit sigma-delta modulators (EAMs) for wide-band applications. Our approach is based on two resonator topologies, high-Q cascade-of-resonator-with-feedforward (HQCRFF) and low-Q cascade-of-integrator-with-feedforward (LQCEFF). Because of in-band zeros introduced by internal loop filters, the proposed architecture enhances the suppression of the in-band quantization noise at a low OSR. The HQCRFF-based modulator with single-bit quantizer has two modes of operation, modulation and oscillation. When the HQCRFF-based modulator is operating in oscillation mode, the feedback path from the quantizer output to the input summing node is disabled and hence the modulator output is free of the quantization noise terms. Although operating in oscillation mode is not allowed for single-stage SigmaDeltaM, the oscillation of HQCRFF-based modulator can improve dynamic range (DR) of the multistage (MASH) SigmaDeltaM. The key to improving DR is to use HQCRFF-based modulator in the first stage and have the first stage oscillated. When the first stage oscillates, the coarse quantization noise vanishes and hence circuit nonidealities, such as finite op-amp gain and capacitor mismatching, do not cause leakage quantization noise problem. According to theoretical and numerical analysis, the proposed MASH architecture can inherently have wide DR without using additional calibration techniques"
- keywords2 =  ["sigma delta modulators", "analog-to-digital converters ", "multistage ", "multibit quantizer", "dynamic range improvement"]

text3 = "An ontology modelling perspective on business reporting. In this paper, we discuss the motivation and the fundamentals of an ontology representation of business reporting data and metadata structures as defined in the eXtensible business reporting language (XBRL) standard. The core motivation for an ontology representation is the enhanced potential for integrated analytic applications that build on quantitative reporting data combined with structured and unstructured data from additional sources. Applications of this kind will enable significant enhancements in regulatory compliance management, as they enable business analytics combined with inference engines for statistical, but also for logical inferences. In order to define a suitable ontology representation of business reporting language structures, an analysis of the logical principles of the reporting metadata taxonomies and further classification systems is presented. Based on this analysis, a representation of the generally accepted accounting principles taxonomies in XBRL by an ontology provided in the web ontology language (OWL) is proposed. An additional advantage of this representation is its compliance with the recent ontology definition metamodel (ODM) standard issued by OMG"
- keywords3= ["enterprise information integration and interoperability", "languages for conceptual modelling", "ontological approaches to content and knowledge management", "ontology-based software engineering for enterprise solutions", "domain engineering"]

**Cosine similarity score**

|Rank|Extraction method| Cosim (text1) | Cosim (text2)| Cosim (text3)| Cosim (avg) |
|------|-----------------|--------|-------|-------|------|
|1|PKE SingleRank       | 1.42   | **1.44**  | 2.17  | **1.67** |
|1|PKE TopicalPageRank  | 1.42   | **1.44**  | 2.17  | **1.67** |
|3|PKE PositionRank     | 1.48   | 1.37  | 2.13  | 1.66 |
|4|PKE TextRank         | 1.25   | 1.2   | **2.22**  | 1.56 |
|5|KeyBERT              | **1.67**   | 1.41  | 1.38  | 1.49 |
|6|YAKE                 | 1.32   | 1.33  | 1.32  | 1.33 |
|7|PKE Kea              | 1.33   | 0.92  | 1.56  | 1.27 |
|8|PKE TfIdf            | 1.32   | 0.92  | 1.56  | 1.27 |
|9|PKE TopicRank        | 1.33   | 1.06  | 1.3   | 1.23 |
|10|PKE FirstPhrases     | 1.29   | 1.18  | 1.17  | 1.20 |
|11|PKE KPMiner          | 1.17   | 0.92  | 1.45  | 1.18 |
|12|SpaCy                | 1.19   | 0.72  | 0.84  | 0.92 |
|13|RAKE                 | 0.87   | 0.46  | 0.32  | 0.55 |

Bovenstaande tabel geeft de cosine similarity score (Lahitani et al., 2016) weer tussen de bestaande keywords van de drie eerder genoemde teksten en de voorspelde keywords van de verschillende keyword-extractors van hoog naar laag in gemiddelde score. De cosine similarity score geeft weer wat de afstand is tussen twee woorden (in dit geval echte keywords en voorspelde keywords). 

Uit de testresultaten blijkt dat de **performance** van PKE SingleRank gemiddeld het beste is op de gebruikte testdata. Bovendien bleek de PKE methodiek in zijn algemeen sneller te werken dan modellen als KeyBERT of YAKE, gezien de lagere **resource demands**. In termen van **explainability** en **model complexity** heeft PKE Singlerank een specifieke methode om keywords te extracten die gemakkelijker te begrijpen is dan het gebruik van een voorgetraind model als KeyBERT of supervised modellen als PKE Kea. PKE Singlerank werkt minder goed als het grote hoeveelheden tekst moet verwerken. Academische papers zijn relatief klein, dus PKE Singlerank is **scalable** genoeg voor ons onderzoek. Hierom is uiteindelijk besloten om PKE SingleRank toe te passen in het prototype als definitieve keyword extraction methode. 

*Lahitani et al., 2016*: Lahitani, A. R., Permanasari, A. E., & Setiawan, N. A. (2016). Cosine similarity to determine similarity measure: Study case in online essay assessment. 2016 4th International Conference on Cyber and IT Service Management. doi:10.1109/citsm.2016.7577578 
# Question generation (Oscar)

Om vragen te generen is er gebruik gemaakt van de Automodel functionaliteit van de transformer library van huggingface.  
Hierbij zijn de gevonden keywords die uit de keyword extractie komen gebruikt als antwoorden.  

Dez antwoorden zijn gebruikt in een vooraf [gefinetunede T5 model](https://huggingface.co/mrm8488/t5-base-finetuned-question-generation-ap) in combinatie met de oorspronkelijke tekst in de volgende manier:
``` 
input_text = "answer: %s  context: %s </s>" % (answer, context)
```
Deze input_text wordt getokenizer en daarna door het model gehaald. Het resultaat hiervan wordt gedecode om uiteindelijk een vraag te genereren.

In [deze notebook](https://gitlab.fdmci.hva.nl/maai/2022-2023-1-b2/team-3/-/blob/main/team/individual/Oscar%20Oosterling/Minisymposium/Question_Generation.ipynb) is hier meer over te lezen.



# Text difficulty (Sander)

In iteratie 1 zijn een aantal text difficulty measures toegepast op een kleine dataset van 3 papers, ter verkenning en experimentatie. De measures in kwestie waren:

 <br>**Tokenized measures**
 - MATTR (Moving Average Type Token Ratio)
 - HD-D (Hypergeometric Distribution Diversity index)
 - MTLD (Measure of Textual Lexical Diversity )

 <br>**Syllables measures**
 - Flesch-reading index
 - SMOG-index

 De papers in kwestie waren een over AI (Paper 1), een zelfgeschreven paper over mondkapjes en Computer Vision (Paper 2) en tenslotte een paper over jaloezie/liefde. Om de experimenten uit te kunnen voeren is er gebruik gemaakt van de LexicalRichness python library, die vele text measures bevat van zowel tokenized als syllables. 
 De resultaten uit de tokenized measures experimenten waren als volgt:

|Measure|Paper 1|Paper 2|Paper 3|
|-------|-------|-------|-------|
| MATTR |0.8077 |0.7475 |0.8020 |
| HD-D  |0.8613 |0.8017 |0.8239 |
| MTLD  |88.82  |54.54  |85.86  |

Hieruit valt op te maken dat Paper 2 op alle drie measures lager scoort, wat logisch is gezien deze paper door een teamlid is geschreven in tegenstelling tot de andere twee papers. Daarnaast moet er opgemerkt worden dat de measures niet met elkaar vergeleken kunnen worden, gezien de gebruikte schaal van de drie measures niet met elkaar overeen komen.

In de tweede iteratie zijn de syllables measures nog eens over de drie papers in kwestie gehaald, de resultaten hieruit waren als volgt:

|Measure|Paper 1|Paper 2|Paper 3|
|-------|-------|-------|-------|
| Flesch-Reading Index |51.78 | 53.71 |42.55 |
| SMOG Index  |13.1 |13.0 |14.8|

De SMOG Index vertaalt het niveau van de tekst naar een zogenaamde 'grade', het engelse woord voor een groep of jaar op school. Een SMOG index van 5 zou dan bijv. betekenen dat de tekst gelezen kan worden op het niveau van iemand uit groep 5. De Flesh-Reading index daarentegen ranked een tekst op een schaal van 120 tot 0, waarbij een score van 120 een hele eenvoudige tekst aanduidt en een score van 0 juist een hele lastige. De resultaten hierboven laten zien dat beide syllables measures de zelfgeschreven paper als eenvoudigste achten. 

Aan de hand van de (resultaten van de) experimenten hierboven vermeld, is er voor gekozen om de Flesh-Reading Index toe te passen in het prototype vanwege twee hoofdredenen:
   - Flesh-Reading Index maakt naast lettergrepen ook gebruik van het aantal zinnen in een tekst. Preprocessing leestekens uit de tekst is hierdoor niet langer nodig en maakt de tekstverwerking een stuk eenvoudiger.
   - De schaal van Flesh-Reading Index is een stuk gevarieerder/breder, van 120 naar 0. Hoewel SMOG heel erg goed zou scoren op explainability, bevindt de score van SMOG zich vrijwel altijd tussen de 8 en 16. Flesh-Reading Index laat daarentegen ook vaak scores boven de 90 zien voor eenvoudige teksten en onder de 40 voor lastige teksten. De MTLD methode kent ook een grote schaal, maar vereist weer een hoop preprocessing.



# Summarizer (Sander)

In de tweede iteratie stond er op de planning om te werken aan leerdoelen B3 en B4. Hierom is er besloten om onder andere een eigen summarizer te bouwen voor in de SKORT Tool. 

Als dataset voor de summarizer is er gekozen voor een dataset van nieuwsartikelen, en bijbehorende korte samenvattingen, van de CNN en Daily Mail. Andere datasets die zijn onderzocht waren: 
   - BillSum (Een dataset die samenvattingen bevat van Amerikaanse (specifiek Californië) wetgevingen)
   - SAMSum (Een dataset die samenvattingen bevat van langdurige chatberichten)
   - BigPatent (Een dataset die handgeschreven samenvattingen bevat van patenten)
   - Multi-Xscience (Een dataset van samenvattingen over wetenschappelijke artikelen)

De CNN/Daily Mail dataset is voornamelijk gekozen vanwege de ruime omvang, zo'n 300.000 artikelen met bijbehorende samenvattingen zijn hier beschikbaar. De artikelen in deze dataset bevatten minstens 300 woorden. Ethisch gezien voldoet de dataset ook aan een aantal punten: 
   - Privacy. De teksten uit de CNN/Daily Mail zijn nieuwsartikelen, bij het opstellen van deze artikelen door CNN is er al gelet op de privacy van de in de artikelen genoemde personen. Namen, gegevens en dergelijke komen daarom ook niet voor in de dataset.
   - Fairness. De teksten uit de CNN/Daily Mail zijn nieuwsartikelen, geen opiniestukken. Hierom zullen er geen opinies van mogelijk biased auteurs in de artikelen voorkomen en zullen de artikelen in de dataset objectief zijn. 
   - Transparency. De dataset is opgesteld uit nieuwsartikelen van de CNN/Daily Mail uit de periode 2007-2015, de auteurs van de dataset vermelden dit en verdere informatie op hun pagina. 
   - Compliance. De dataset heeft een Apache License 2.0, een veelgebruikte open-source software license dat geacht wordt te voldoen aan de wetgeving omtrent het gebruik van online verkrijgbare datasets.

Ethische punten waar de dataset niet aan voldoet of niks over te vinden is:
   - Consent. Op de pagina van de dataset wordt niet vermeld of voor (ieder) artikelen de goedkeuring van de auteurs is gevraagd.
   - Security. De dataset is online makkelijk verkrijbaar en dus ook niet beveiligd.
 

Om het model compact genoeg te houden voor het trainen op de HvA servers, zijn 20000 artikelen (niet specifiek gekozen) uit de gehele dataset gehaald. Van deze 20000 artikelen zijn er vervolgens 5000 bewaard voor de testset, waardoor er 15000 artikelen overbleven voor de trainset. De 20000 artikelen hebben gemiddeld 251 woorden per artikel. Het langste artikel bevat 1310 woorden en het kortste artikel bevat 52 woorden. Een grafiek betreffende deze artikellengtes staat hieronder weergegeven. Hierin geeft de word count de hoeveelheid woorden in een artikel weer en de density welk percentage van de artikelen deze word count bevat.

![SummarizerWordCount](WordDensitiesSummarizer.png)  

Daarnaast bevat de grafiek hieronder informatie over welke woorden het vaakst voorkomen in de dataset. Hierbij is het belangrijk om te vermelden dat 'wa' en 'ha' de woorden 'was' en 'has' zijn maar in de grafiek verkeerd zijn geplaatst.

![WordFrequency](WordFrequency.png)

Voordat de woorden in een artikelen door een Tokenizer worden gehaald, worden eerst alle leestekens uit de artikelen gefilterd totdat enkel cijfers en letters overblijven. Daarnaast worden aan de samenvattingen van de artikelen twee stopwoorden toegevoegd: "START" en "END". Deze zijn benodigd voor het gebruik in het encoder-decoder model. Nadat de woorden in de artikelen zijn getokenized, kan het model getraind worden. Het model is zoals eerder vermeld een encoder-decoder model, waarbij de encoder en de decoder zijn opgesteld uit LSTM units. Het originele model bestond uit 500 (!) LSTM units voor de encoder en 500 (!) LSTM units voor de decoder, wat zorgde voor een totaal van meer dan 70,000,000 modelparameters. Dit bleek echter te veel te zijn voor het geheugen van de HvA servers te zijn, waarnaar het model eerst is gedownscaled naar een operationele 56,253,951 modelparameters, de uiterste limiet waarop het model nog gerund kon worden. 

![ModelParameters](ModelParameters.png)

Dit model trainde echter verre van optimaal en ook iteraties daaropvolgend bleken niet opperbest. (zie resultaten hieronder). 

Iteratie|Iteratie 1 | Iteratie 2 | Iteratie 3 | Iteratie 4 | 
:-------:|:----------:|:-----------:|:-----------:|:-----------:
Resultaten|![](SumRes_Adam_LTSM250_Drop0.4.png)|![](SumRes_Adam_LTSM69_Drop0.5.png)|![](SumRes_Adam_LTSM320_Drop05.png)|![](SumRes_Adam_LTSM250_Drop0.5_40k.png)
Optimizer | Adam |  Adam | Adam | Adam 
LTSM units | 250 | 69 | 320 | 250
Dropout | 0.4 | 0.5 | 0.5 | 0.5
Artikelen | 20000 | 20000 | 20000 | 40000

In de laatste iteratie is het aantal artikelen wat verhoogd, echter bleek dit het model zodoende te vergroten dat dit niet langer gerund kon worden zonder de LSTM units weer te verlagen. Desondanks bleef het model hevig overfitten. 

Verder is het model nog op performance getest, op de 5000 overgebleven artikelen uit de testset. Als performance metric voor de testset is er gekozen voor ROUGE. ROUGE is een veelgebruikt en gerenommeerd metric voor het evalueren van samenvattingen en is in staat om te letten op grammaticale correctheid en vloeiendheid. Verder maakt ROUGE gebruik van n-wordoverlaps, wat het mogelijk maakt om in elke taal een samenvatting te kunnen evalueren (zo lang de samenvatting waarmee je vergelijkt wel in de zelfde taal is geschreven als de gegenereerde samenvatting). 
Het getrainde model haalde lage ROUGE scores bij elke iteratie, wat verwacht kon worden kijkend naar de trainingsresultaten. De ROUGE resultaten waren als volgt:

Iteratie|Iteratie 1 | Iteratie 2 | Iteratie 3 | Iteratie 4 | 
:-------:|:----------:|:-----------:|:-----------:|:-----------:
ROUGE-L (f1)  | 0.04 | 0.03 | 0.04 | 0.06 |

Uit de tabel hierboven valt dus op dat de performance van het model verre van optimaal is, zeker als er vergeleken wordt met summarizer modellen van huggingface. Zo heeft distilbart-xsum-12-1 een ROUGE-L (f1) score van 0.33 en een latere distilbart-xsum-9-6 model zelfs een score van 0.36. 

Uiteindelijk is er dan ook besloten om het zelfgetrainde model niet in het SKORT model toe te voegen, maar om een pretrained model van BART te gebruiken in het prototype. Dit pretrained model in kwestie is een distilbart-12-6-cnn geworden. 


# Term definition generation (Kristo)
Het laatste onderdeel waar SKORT over beschikt is het genereren van definities bij vaktermen die voorkomen in de geuploade paper. Om deze definities te genereren is de ChatGPT API gebruikt. 

Er zijn verschillende aanbieders van NLP API's, zoals IBM Watson, Google Cloud Natural Language, of Microsoft Azure Text Analytics. Deze API's bieden functies voor het verwerken van menselijke taal, zoals analyseren hoevaak bepaalde woorden voorkomen, sentimentanalyse of zinssegmentatie. In dit project wordt de ChatGPT API toegepast om definities van vaktermen te genereren, gezien de hype die momenteel rond de chatbot heerst volgens [CNET](https://www.cnet.com/tech/computing/why-everyones-obsessed-with-chatgpt-a-mind-blowing-ai-chatbot/).

ChatGPT is een chatbot van OpenAI en is getraind op het GPT-3 (Generative Pre-trained Transformer 3) taalmodel dat bestaat uit 175 miljard parameters (800GB opslag(!)). Hiermee is GPT-3 het grootste taalmodel van dit moment, volgens [AI Business](https://aibusiness.com/nlp/7-language-models-you-need-to-know). GPT-3 is getraind op tekstdata van tot september 2021 en is gespecialiseerd om te voorspellen wat het volgende woord in een zin is. De chatbot zal om eerdergenoemde redenen als API in de cloud gebruikt worden. De grootte van het model toont wel aan dat dit een goed doorgetraind model is, en het is volgens menig mens de beste chatbot van het moment volgens [The Algorithmic Bridge](https://thealgorithmicbridge.substack.com/p/chatgpt-is-the-worlds-best-chatbot), .

Wetenschappelijke artikelen bevatten relatief moeilijke vaktermen om te beschrijven waar het artikel over gaat. Voor lezers uit hetzelfde onderzoeksgebied zijn de vaktermen eenvoudig te begrijpen, maar voor anderen niet. Daarom heeft SKORT de optie geïnfiltreerd om definities van de vaktermen te genereren die lezers van andere domeinen kunnen helpen de basisconcepten van het onderzoek te begrijpen.

Om het genereren van definities te realiseren in SKORT, waren een aantal stappen nodig. Allereerst is de tekst ge-extract uit de PDF-file met behulp van de PyPDF2-library in Python. Vervolgens is de tekst voorbewerkt. Dit was nodig, omdat de ChatGPT API vanuit de cloud maar 2049 tokens (input en output samen) kan verwerken. Een wetenschappelijk artikel bevat uiteraard gemiddeld meer dan 2049 tokens. Om het aantal tokens te verlagen, zijn allereerst de referenties verwijderd. Vervolgens zijn alle stopwoorden en tekens verwijderd met de nltk-library. Daarna zijn alle duplicaties in woorden verwijderd, waardoor er alleen nog unieke woorden overbleven. Deze unieke woorden waren de invoer voor de ChatGPT API en alle vaktermen worden geëxtraheerd. Deze vaktermen waren opnieuw de invoer voor de ChatGPT API, maar dit keer heeft ChatGPT de definities van de vaktermen gegeven. De vaktermen en bijbehorende definities zijn in een dictionary geplaatst. Tot slot zijn de vaktermen opgezocht in de originele tekst en is de definitie bij de vaktermen geplaatst in een tooltip.

De resultaten zijn [hier](../../../team/individual/Kristo Wind/Mini Symposium/Vakblad_Kristo_Wind_Final.ipynb) te vinden.

### Resource Demand (Model engines ChatGPT API)
Er is ook een resource demand experiment uitgevoerd door alle mogelijke model engines van ChatGPT API te testen op rekentijd en kwaliteit van de geextraheerde termen bij het verwerken van mijn eigen paper uit het vorige blok. Er is alleen gekeken naar de ChatGPT API, aangezien ChatGPT momenteel een enorme hype is en de betrokkenen bij het project benieuwd waren naar de resultaten die deze API zou opleveren. Ook gebruik ik om deze redenen deze API in mijn eigen onderzoek. Er zijn 14 model engines binnen ChatGPT waar mee gespeeld kan worden, dus de resource demand zal getest worden op alle mogelijke model engines waar ChatGPT over beschikt. De input aan de API bestond uit de volgende prompt: f"Can you extract AI jargon from the following text?: {text}", waarbij text bestaat uit een string van 739 unieke geextraheerde woorden uit de [input paper](AVAA_Article_K_Wind.pdf). De resultaten zijn in onderstaande tabel te vinden.

| Model Engine  | Rekentijd (s)  | Output | Num. of elements in list |
|---|---|---|---|
|babbage|00:09|['ization training samples this data not to be expected to be accurate however results generalize can be used to determine generalize accuracy of ai algorithms in general ... people in a specific country in a specific time period in a specific country (54)']|1|
|ada|00:08|[' error not control of test results a show the result average result of all the most important 1.2.1.1.2.2.2 ... 2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2']|1|
|davinci|00:34|['ization protocols these results show significant improvement accuracy age-invariant facial recognition over previous studies achieved using deep ... in identifying individuals regardless of age this result shows that age-invariant facial recognition using deep conv']|1|
|curie|00:10|[' data-analysis results used this suggests future research could improve performance could include additional factors could explore further factors ... other factors could include other factors could include other factors could include other factors could include other factors could include']|1|
|text-davinci-001|00:13|[' deviation table av-nn face recognition works well within age range con ... in the database are of people who have been verified to be of legal age to buy alcohol']|42|
|text-davinci-002|00:28|['izing databases common standardize order standardizing performed facial-recognition systems ... systems’ accuracy systems’ standardization important aspect recognition systems’']|1|
|text-davinci-003|00:06|['deep networks', ' convolutional cnns', ' siamese neural network', ' aa-nn', ... ,' embedding', ' binary prediction', ' detection-threshold', ' verification-ratio.']|15|
|code-davinci-002|00:50|[' deviation deviation-values high standard-deviation-value indicates difference-values close close-values imply equally small-values distant-values ... vper-values pin-values vper-values pin-values vper-values pin-values vper-values pin-values vper-values pin-values vper-values pin-values vper-']|1|
|text-ada-001|00:05|[' family lines down to ersatz\n\nthe following are three sentences from a research paper ...recognition-based even if they don't have an age-related change in facial appearance.']|7|
|text-curie-001|00:10|[' deviation age difference largest participant results smallest average...st participant results smallest average difference largest participant results']|1|
|curie-instruct-beta|00:02|['ization limitations should be taken into account modifications to current ... ' the current method can be used to detect individuals in a group of individuals of different ages.']|2|
|davinci-instruct-beta|00:03|['ization algorithm']|1|
|text-babbage-001|00:09|[' deviation error detect person correctly recognized accurately error rate error rate error rate error rate error rate error rate error ... rate error rate error rate error rate error rate error rate error rate']|1|
|code-cushman-001|00:13|[' age-related changes in head and neck facial expression determined face expression ... trained with different data and therefore can be used to classify new']|8|

Zoals opvalt uit bovenstaande tabel, geeft alleen de model-engine 'text-davinci-003' echte termen terug en is de model engine snel qua rekentijd. Hierom is gekozen voor de model engine 'text-davinci-003' voor dit onderzoek. 
# Feedback van testpersonen op paper prototype binnen klas (Sander)

### Testpersonen: MAAI studenten
#### Het paperprototype is duidelijk/voldoende compleet/voldoende gedetailleerd.
  - Tip: I'tje op highlight optie, waarop bepaald het model?
  - Tip: Uitleg over de moeilijkheidsbepaling zou handig zijn, waar is dit op gebasseerd?
  - Tip: Zet niet alle opties aan bij het begin
  - Tip: Mist info knopje
  - Tip: Ben vergeten het te proberen, maar kan je dan ook eerst op de definities klikken en dan pas op keywords
  - Tip: Applicatie is niet duidelijk, PDF heeft geen website (?????), Popup kan niet context zien
  - Tip: Kleur
  - Tip: Info knop voor moeilijkheidsgraad/keywords ontbreekt, knopje terug ontbreekt

  - Top: Duidelijk idee en overzichtelijk prototype 
  - Top: De applicatie geeft niet te veel opties en is lekker simpel
  - Top: Simpel maar duidelijk
  - Top: Prototype is redelijk simpel, geen onnodige knoppen en je komt er makkelijk doorheen
  - Top: Duidelijk
  - Top: Erg duidelijk en goed doorheen te lopen zonder uitleg
  - Top: Mooie details, duidelijk wat je doet
  - Top: Heel duidelijk
  - Top: Eenvoudig en overzichtelijk

#### Het achterliggende idee is goed.
 - Tip: Waarom de highlight/descriptie uit zetten, daar is de tool toch voor bedoeld?
 - Tip: Het zou fijn zijn om bij de definities van termen relevante papers te tonen
 - Tip: Het voegt niet heel veel toe aangezien ik keywords ook kan googlen
 - Tip: Misschien wat extra features toevoegen
 - Tip: Misschien fijn als je zelf een moeilijksheidgraad kan bepalen
 - Tip: Startscherm nog niet (????), hover was niet duidelijk, misschien wat meer kleur toevoegen
 - Tip: Misschien meer functionaliteiten
 - Tip: Meerdere documenten tegelijk

 - Top: Chill idee!
 - Top: Handige tool die het lezen van papers een stuk toegankelijker kan maken
 - Top: handig, ik zou het gebruiken
 - Top: Het idee is prima, weet alleen niet of ik het zou gebruiken?
 - Top: Leuk idee
 - Top: Snelle en relevante tool
 - Top: Heel duidelijk wat het idee is
 - Top: Heel bruikbaar
 - Top: Leert over nieuwe concepten

#### Het ontwerp is goed.
 - Tip: SKORT is zo'n random naam (?????)
 - Tip: Uitleg over moeilijkheidsgraad is niet te vinden
 - Tip: Maak het minder druk
 - Tip: Niet helemaal compleet nog
 - Tip: Krijg gelijk alle beschrijvingen van de keywords, terwijl ik er misschien maar één niet begrijp
 - Tip: Misschien meer aesthetic

 - Top: Minimalistisch en overzichtelijk
 - Top: De applicatie geeft niet te veel opties en is daardoor simpel en makkelijk te gebruiken
 - Top: Je hebt al weinig functionaliteit en dat maakt het een fijne en simpele tool
 - Top: Goed ontwerp
 - Top: Zelfde als eerste top
 - Top: Heel duidelijk


Doorgevoerde aanpassingen na deze feedbacksessie:
 - Infoknoppen zijn toegevoegd bij leestijd en moeilijkheidsgraad 
 - Knoppen voor terug en home zijn toegevoegd
 - Keywords poppen niet allemaal meer op na een klik op de button

# Feedback van testpersonen op paper prototype buiten klas (Kristo)

### Testpersoon 1: student (21 jaar, Mechanica & Robotica)
#### Het paperprototype is duidelijk/voldoende compleet/voldonde gedetailleerd.
  - Tip: Toolknop maken
  - Top: Complexiteit

#### Het achterliggende idee is goed.
 - Tip: Doelgroep bepalen
 - Top: Goed uitgewerkt

#### Het ontwerp is goed.
 - Tip: n.v.t.
 - Top: Duidelijk overzicht

### Testpersoon 2: student (24 jaar, Architectuur)
#### Het paperprototype is duidelijk/voldoende compleet/voldonde gedetailleerd.
 - Tip: Optie tot filteren per opleiding
 - Top: Duidelijke user interface

#### Het achterliggende idee is goed.
 - Tip: n.v.t.
 - Top: Handige tool voor research

#### Het ontwerp is goed.
 - Tip: n.v.t.
 - Top: n.v.t.

### Testpersoon 3: student (23 jaar, Studentassistent)
#### Het paperprototype is duidelijk/voldoende compleet/voldonde gedetailleerd.
 - Tip: Relevante papers lijst
 - Top: Reading time/highlights

#### Het achterliggende idee is goed.
 - Tip: n.v.t.
 - Top: n.v.t.

#### Het ontwerp is goed.
 - Tip: n.v.t.
 - Top: Simpel

### Testpersoon 4: Docent (34 jaar, docent ICT, Mechanica & Robotica)
#### Het paperprototype is duidelijk/voldoende compleet/voldonde gedetailleerd.
 - Tip: Maak de layout vloeiend en gebruik geen Wikipedia als bron.
 - Top: Duidelijke user interface, vanzelfsprekend.

#### Het achterliggende idee is goed.
 - Tip: Maak de zoektocht makkelijk. Zoals suggesties?
 - Top: Gaat snel, direct resultaat.

#### Het ontwerp is goed.
 - Tip: Stijl. Kijk naar soortelijke als voorbeeld.
 - Top: If it ain't broke...

Aanpassingen die na deze feedbacksessie nog zijn doorgevoerd:
- Layout is wat overzichtelijker gemaakt, paper is nu te lezen op de linkerkant van de pagina, buttons bevinden zich op de rechterkant van de pagina.
- SciHub links zijn toegevoegd als optie voor inladen, zodat de gebruiker niet eerst nog de paper hoeft te downloaden als pdf.

# Feedback uit peer-review (16-12-2022)

- **A1**
   - Technische en functionele requirements goed uitgelegd, kan wel concreter. Verder miste juridische eisen, is het gebruik van sci-hub links wel zo handig?
   - Eisen zijn getoetst bij de stakeholders, eisen waren opzich goed opgesteld. 
- **A3**
   - Onduidelijk hoe deze oplossing tot stand is gekomen. Wel goed uitgedacht (flowchart, storyboard, impact of mistakes).
   - Niet duidelijk gemaakt welke keuzes zijn gemaakt, waarom dit paper prototype? Duidelijk welke iteraties zijn uitgevoerd, maar niet specifiek wat er aangepast is aan het prototype.  
- **A4**
   - Mogelijke beperkingen duidelijk toegelicht. 
   - Wij hebben hier niks over gezien, wel iets over ethiek. Ethiek is voor de context wel goed uitgewerkt. 
- **B1**
   - Success definition duidelijk weergegeven. Etische beperkingen benoemd
   - Voelt nog erg generiek, hoe maak je dit specifiek in je systeem? Ethische aspecten over nagedacht, maar nog geen handelingen voor uitgevoerd. Als je een eigen dataset maakt hoe voorkom je dan bias?  
- **B2**
   - In depth uitleg over modellen en ook goed verschillende methode vergeleken (10 stuks ofzo :O??!?!??!!)
   - Goed dat er veel verschillende modellen met elkaar zijn vergeleken!  
- **B3**
   - Het plan is om een eigen dataset te maken en is ook de meest betrouwbare bron. Kijk vooral op huggingface voor inspiratie.  
   - Jullie maken gebruik van bestaande modellen, wel tools gebruikt om dataset inzicht te krijgen. Naar ons idee nog niet heel veel gedaan met data preparatie.
- **B4**
   - Uitgebreide evaluatie met duidelijke argumentatie.
   - Bestaand model gebruikt, dus dit is moeilijk te beoordelen. Jullie hebben wel de modellen geëvalueerd. 
- **B5**
   - Indrukwekkend prototype met werkende functies. Design duidelijk, maar paper was klein en moeilijk te lezen. 
   - Prototype is getest, feedback is niet heel specifiek genoemd. Demo is al super goed! 


**Conclusie** 
<br> Over het algemeen was de feedback op onze presentatie positief, met name betreffende de uitwerking van het prototype. Wel werd er aangemerkt dat het leerdoel A3 en B3 nog duidelijker uitgelicht hadden kunnen worden. Uit de feedback hebben we tevens de volgende punten gehaald voor verbetering in de tweede iteratie en voor de ontwerpreview van 23 december:
 - Requirements moeten concreter opgesteld worden, met name kijken naar juridische eisen
 - Duidelijker noteren hoe het idee tot stand is gekomen en wat er is aangepast na elke testsessie met het prototype
 - Ethisch aspect moet in het algemeen beter aan bod komen
 - Het ontwikkelen en trainen van een eigen model, met ook een eigen dataset, zal in de tweede iteratie moeten worden aangepakt.  


 # Feedback uit ontwerpreview

 Feedback is afkomstig van docent MAAI, Sonja Rouwhorst. 

 **A3. Je verkent en analyseert de oplossingsrichtingen voor een vraagstuk en ontwerpt een AI-oplossing volgens een (gangbare) ontwerpmethodiek.**

Jullie doorlopen de stappen van een ontwerpproces en maken verbeteringen in je ontwerp gaandeweg.  Een paar onderdelen vind ik heel sterk:
   - De process flow van huidige en toekomstige proces geeft duidelijk aan wat de toegevoegde waarde van jullie product moet worden 
   - Mooie flowchart
   - Goed verdiept in domein

Het ontwerp van de applicatie is erg basic. Ik zie twee punten waarvan ik heel graag zie dat jullie die nog veranderen:

   - het scrollen door de tekst gebeurt op een vreemde plek, boven de tekst, is vreemd
   - Het high lighten van belangrijke termen is goed. In plaats van dat je aan de rechterkant, dan handmatig die term moet overtypen om een definitie/synoniem en antoniem    te kunnen zien, zou ik zorgen dat je op zo'n woord kunt klikken en dat er dan op die plek een popup komt met een definitie en tabjes om ook synoniemen en antoniemen te bekijken.

**A5. Je brengt mogelijke ongewenste consequenties van de oplossingsrichting voor de maatschappij in kaart en treedt hierover in gesprek met opdrachtgever en vakgenoten.**

   - Jullie staan goed stil bij mogelijke ongewenste consequenties van de applicatie en mogelijke vormen van bias. 

   - Als het gaat om te bedenken of jullie applicatie goed werkt, merk ik dat ik moeite heb met het begrip 'keyword'. Hierover heb ik ook al een aantal maal met jullie gesproken. Misschien is het handig om hier nog even met jullie coach over te spreken. Wat is de definitie van keyword? Als ik kijk naar jullie process flow zou het moeten gaan over (vak)termen lijkt het. Of gaat het ook over moeilijke woorden? Of beide? 

**B5. Je ontwikkelt een prototype en test deze in de context waarin de oplossing gebruikt gaat worden.**

   - Het idee van het nulmodel om te vergelijken of skort beter gaat zijn is interessant, ik ben benieuwd of jullie hierop gaan terugkomen.

   - Jullie hebben meermaals getest met verschillende testpersonen. Als aandachtspunt wil ik meegeven dat jullie beter laten zien met wie, hoe en waar je test.

**C3. Je verzamelt en verwerkt actief feedback van belanghebbenden en laat zien deze feedback te kunnen gebruiken om je werk te verbeteren.**

   - Jullie schrijven de feedback van de klasgenoten en testpersonen duidelijk op en jullie laten ook beknopt zien wat je met de feedback doet. Ik mis de feedback die jullie coach geeft in je logboek?

**Conclusie**
   - De feedback is over het algemeen positief geacht. In het logboek zal er verduidelijking worden aangebracht betreffende de term "keywords", om ervoor te zorgen dat de lezer onze intentie omtrent gevonden kernwoorden kan begrijpen. Verder zal er informatie worden bijgevoegd bij de resultaten uit de testsessies betreffende de testpersonen (locatie, leeftijd, opleiding).

# Feedback van testpersonen binnen/buiten klas op definitief prototype (Week 8/9)
   - Opzet volgt de werkwijze zoals bij eerdere testsessies met het paper prototype is aangehouden. Waarbij de testpersoon geen tot weinig informatie verkijgt met betrekking tot het prototype en er van de testpersoon gevraagd wordt zelf met het prototype uit de voeten te kunnen. Deze aanpak is gekozen om het prototype te kunnen evalueren op het gebied van gebruiksgemak. Na het voltooien of genoeg testen van het prototype worden een aantal vragen aan de testpersoon gestelt, waarvan de resultaten hieronder zijn weergegeven: 
### Testpersoon 1: student (27 jaar, Mechanica & Robotica)
#### Is het duidelijk wat er in het prototype gebeurt, valt het allemaal te volgen?
   - Ja, het is wel duidelijk. Ik weet wat ik van de verschillende functies kan verwachten. Echter zou ik misschien aanbevelen om sommige functies bij elkaar te groeperen in blokjes, om het wat overzichtelijker te maken.

#### Vertrouw je de aangegeven/gevonden kernwoorden?
   - Ik denk van wel, het is moeilijk zelf te bepalen zonder de hele tekst te lezen natuurlijk, maar de kernwoorden lijken op het eerste oog logisch. Misschien zouden er wat meer dan de huidige 10 kernwoorden gekozen kunnen worden.

#### Begrijp je de manier waarop de leestijd en moeilijkheidsgraad tot stand komt en wordt weergegeven?
   - Hoe het is weergegeven wel, maar de formule voor moeilijksheidgraad met name maakt me niet echt wijzer.

#### In welk onderdeel zou je verbetering willen zien?
   - Duidelijkheid interface kan nog wat verbetering gebruiken, misschien wat meer kleur

#### Zou je deze tool gebruiken en zo nee, waarom niet?
   - Ja, ik zou deze tool wel willen gebruiken, zolang het geen giga .exe bestand is.

#### Welk cijfer zou je zelf de tool willen geven betreffende gebruiksgemak?
   - 8.5

### Testpersoon 2: student (22 jaar, Structural Engineering)
#### Is het duidelijk wat er in het prototype gebeurt, valt het allemaal te volgen?
   - Ja, ik kom er op zich wel doorheen. Echter had het wel handiger geweest als er iets meer tekst ter informatie beschikbaar zou zijn.

#### Vertrouw je de aangegeven/gevonden kernwoorden?
   - Zover ik kan zien staan er geen rare kernwoorden tussen, dus ik denk het wel.

#### Begrijp je de manier waarop de leestijd en moeilijkheidsgraad tot stand komt en wordt weergegeven?
   - Ja, helder.

#### In welk onderdeel zou je verbetering willen zien?
   - Wat meer tekstinformatie op het scherm, of wellicht een tutorial voor eerste gebruikers.

#### Zou je deze tool gebruiken en zo nee, waarom niet?
   - Ja, lijkt me handig.

#### Welk cijfer zou je zelf de tool willen geven betreffende gebruiksgemak?
   - 7

### Testpersoon 3: student (21 jaar, Applied Artificial Intelligence)
#### Is het duidelijk wat er in het prototype gebeurt, valt het allemaal te volgen?
   - Grotendeels wel, zou alleen wel meer informatie betreffende knoppen en functies op prijs stellen.

#### Vertrouw je de aangegeven/gevonden kernwoorden?
   - Ja, ik vertrouw jullie product wel wat dat betreft.

#### Begrijp je de manier waarop de leestijd en moeilijkheidsgraad tot stand komt en wordt weergegeven?
   - Jazeker, geen probleem.

#### In welk onderdeel zou je verbetering willen zien?
   - Wat van die tekstballonnetjes wanneer je over een knop hovert met wat informatie over wat het doet zou een hele goede toevoeging zijn. Daarnaast kan de opmaak ook wel een makeover gebruiken, maar het blijft een prototype natuurlijk.

#### Zou je deze tool gebruiken en zo nee, waarom niet?
   - Ja, ik zou er misschien wel eens mee willen spelen

#### Welk cijfer zou je zelf de tool willen geven betreffende gebruiksgemak?
   - 7


### Testpersoon 4: student (23 jaar, Structural Engineering)
#### Is het duidelijk wat er in het prototype gebeurt, valt het allemaal te volgen?
   - Ik heb wel een beetje moeite met het vinden van de juiste functies zo op het oog, maar ik denk dat dat voornamelijk komt doordat het de eerste keer is. 

#### Vertrouw je de aangegeven/gevonden kernwoorden?
   - Die lijken mij logisch ja.

#### Begrijp je de manier waarop de leestijd en moeilijkheidsgraad tot stand komt en wordt weergegeven?
   - Ik snap de schaal waarmee het is weergegeven, maar van de achterliggende formules heb ik geen verstand.

#### In welk onderdeel zou je verbetering willen zien?
   - Een tutorial toevoegen zou geen overbodige luxe zijn. Daarnaast zou dit prototype misschien beter functioneren als plug-in ipv applicatie.

#### Zou je deze tool gebruiken en zo nee, waarom niet?
   - Ja, lijkt me handig.

#### Welk cijfer zou je zelf de tool willen geven betreffende gebruiksgemak?
   - 6.5


### Testpersoon 5: student (24 jaar, Applied Artificial Intelligence)
#### Is het duidelijk wat er in het prototype gebeurt, valt het allemaal te volgen?
   - Ik kom er uiteindelijk wel uit, maar wat extra hulp zou ik niet verkeerd vinden.

#### Vertrouw je de aangegeven/gevonden kernwoorden?
   - Ja 

#### Begrijp je de manier waarop de leestijd en moeilijkheidsgraad tot stand komt en wordt weergegeven?
   - Lijkt me logisch inderdaad.

#### In welk onderdeel zou je verbetering willen zien?
   - Zwart-wit vind ik persoonlijk niet de meest aantrekkelijke opmaak voor een applicatie, zou wel iets meer hedendaags kunnen zijn. En wellicht kan de snelheid van de applicatie op een aantal punten wat verbeterd worden.

#### Zou je deze tool gebruiken en zo nee, waarom niet?
   - Ja, als alles functioneert zoals het nu doet zou ik het zeker willen gebruiken.

#### Welk cijfer zou je zelf de tool willen geven betreffende gebruiksgemak?
   - 8


### Conclusie
   - Het prototype scoort een ruime voldoende van de testpersonen, ook al is de sample size nogal laag natuurlijk. 
   - Er kunnen nog wat kleine aanpassingen gemaakt worden aan het prototype, zeker met betrekking tot het vergeven van informatie binnen de tool. Hoverknoppen zullen toegevoegd worden en wat meer tekst ter informatie zal toegevoegd worden.
   - Aan de opmaak valt met de geringe overgebleven tijd weinig aan te veranderen.
   - Een aantal functies zullen wat logischer binnen de tool opgedeeld worden, indien mogelijk binnen blokjes.

